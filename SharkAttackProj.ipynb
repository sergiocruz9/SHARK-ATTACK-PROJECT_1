{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9150c4e",
   "metadata": {},
   "source": [
    "Scroll down to see what is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7a1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from thefuzz import process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82109b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"https://www.sharkattackfile.net/spreadsheets/GSAF5.xls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4868c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"pdf\", \"href formula\", \"Source\", \"href\", \"Case Number\", \"Case Number.1\", 'original order', 'Unnamed: 21', 'Unnamed: 22'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51450137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning Type\n",
    "df.dropna(subset=[\"Type\"], inplace=True)\n",
    "df[\"Type\"] = df[\"Type\"].str.strip().str.title()\n",
    "df[\"Type\"] = df[\"Type\"].replace({\"Unverified\": \"Unknown\", \"Under Investigation\": \"Unknown\", \"Unconfirmed\": \"Unknown\", \"?\": \"Unknown\", \"Questionable\": \"Unknown\", \"Invalid\": \"Unknown\", \"Watercraft\": \"Unprovoked-like\", \"Sea Disaster\": \"Unprovoked-like\", \"Boat\": \"Unprovoked-like\"})\n",
    "# unproked-like means they did not mean to porvoke the shark but the shark got provoked by the noise or the movement of the boat ext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee1d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provoked value\n",
    "\n",
    "def full_type(value):\n",
    "    if value == \"Unprovoked\":\n",
    "        return \"Unprovoked\"\n",
    "    elif value == \"unprovoked\":\n",
    "        return \"Unprovoked\"        \n",
    "    elif value == \"Provoked\":\n",
    "        return \"Provoked\"\n",
    "    elif value == ' Provoked':\n",
    "        return \"Provoked\"\n",
    "    elif value == \"Sea Disaster\":\n",
    "        return \"Sea Disaster\"\n",
    "    elif value == \"Watercraft\":\n",
    "        return \"Watercraft\"\n",
    "    elif value == \"Boat\":\n",
    "        return \"Watercraft\"\n",
    "    else:\n",
    "        return \"Questionable\"\n",
    "\n",
    "df2=df[\"Type\"].apply(full_type).str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c23cb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gender\n",
    "df[\"Sex\"] = df[\"Sex\"].str.strip().str.title().replace({\"Male\" : \"M\", \"M X 2\" : \"M\", \"Lli\" : \"M\", \".\" : \"F\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1893c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Injury Column \n",
    "\n",
    "# 1st: formatting, cleaning spaces, lowe case and strange characters\n",
    "\n",
    "df[\"Injury\"] = (\n",
    "    df[\"Injury\"]\n",
    "      .astype(\"string\")\n",
    "      .str.strip()\n",
    "      .str.replace(r\"\\s+\", \" \", regex=True)   \n",
    "      .str.lower()                             \n",
    ")\n",
    "\n",
    "#2 remove garbage like unknown, na, -, \"?\" without dropping \"no injury\":\n",
    "\n",
    "placeholders = {\"unknown\",\"unk\",\"n/a\",\"na\",\"none\",\"null\",\"-\", \"--\", \"—\", \"?\", \"\"}\n",
    "df.loc[df[\"Injury\"].isin(placeholders), \"Injury\"] = pd.NA\n",
    "\n",
    "import re\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "s = df[\"Injury\"].astype(\"string\")\n",
    "\n",
    "# 1) detect \"no injury\" first\n",
    "noinjury_rx = r\"\\bno injur(?:y|ies)\\b|\\buninjur(?:ed|y)\\b|\\bno injury to (?:\\w+)\\b\"\n",
    "noinjury = s.str.contains(noinjury_rx, na=False)\n",
    "\n",
    "# 2) phrases that explicitly negate fatal\n",
    "nonfatal_phrase = s.str.contains(r\"\\bnon[-\\s]?fatal\\b|\\bnot fatal\\b|\\bsurvived\\b\", na=False)\n",
    "\n",
    "# 3) fatal markers (only if not explicitly non-fatal)\n",
    "fatal_any = s.str.contains(r\"\\bfatal\\b|\\bkilled\\b|\\bdied\\b|\\bbody not recovered\\b|\\bcarried off\\b\", na=False)\n",
    "fatal_flag = (~nonfatal_phrase) & fatal_any\n",
    "\n",
    "# 4) build the binary label\n",
    "df[\"fatal_non_fatal\"] = pd.NA\n",
    "df.loc[fatal_flag, \"fatal_non_fatal\"] = \"fatal\"\n",
    "df.loc[~fatal_flag & s.notna() & (s.str.len() > 0), \"fatal_non_fatal\"] = \"non-fatal\"  # includes \"no injury\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191ac197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activity\n",
    "condition_1 = df[\"Activity\"].str.lower().str.split().str.len() > 1\n",
    "condition_2 = df[\"Activity\"].str.replace(\" \", \"_\")\n",
    "df.loc[condition_1, \"Activity\"] = condition_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd08410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning SPECIES column\n",
    "condition_1 = df[\"Species \"].str.lower().str.split().str.len() > 1\n",
    "condition_2 = df[\"Species \"].str.replace(\" \", \"_\")\n",
    "df.loc[condition_1, \"Species \"] = condition_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "957dc2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning name column:\n",
    "#format all to string type and apply correct capitalization type (lower) for better cleaning process + eliminate any special characters\n",
    "df[\"Name\"] = (df[\"Name\"].astype(\"string\")).str.strip().str.lower().str.replace(\"[()€$]\", \"\", regex=True)\n",
    "#remove innecesary titles and suffixes = \n",
    "titles = [\n",
    "   \"mr\",\"mrs\",\"ms\",\"miss\",\"mstr\",\n",
    "    \"dr\",\"drs\",\"doctor\",\"prof\",\"sir\",\"madam\",\"madame\",\n",
    "    \"fr\",\"rev\",\"pastor\",\"pr\",\n",
    "    \"capt\",\"cpt\",\"captain\",\n",
    "    \"lt\",\"sgt\",\"cpl\",\"pvt\",\"ens\",\"col\",\"maj\",\"gen\",\"cmdr\",\"comdr\",\"commander\",\"adm\",\n",
    "    \"officer\",\"crewman\",\"crew\",\"seaman\",\"able\",\"bosun\",\n",
    "    \"señor\",\"señora\",\"señorita\",\"sr\",\"sra\",\"srita\",\"doña\",\"don\",\n",
    "    \"capitaine\",\"monsieur\",\"mademoiselle\",\"madamoiselle\",\n",
    "    \"capitan\",\"capitán\",\"ingeniero\",\"ing\",\"lic\",\"arq\",\"arquitecto\"]\n",
    "suffixes = [r\"jr\", r\"sr\", r\"iii\", r\"ii\", r\"iv\"]\n",
    "removepatterns= \"|\".join(titles) + \"|\".join(suffixes) + r\"|\\.\"  #add period as well\n",
    "df[\"Name\"] = df[\"Name\"].str.replace(removepatterns, \"\", regex=True)\n",
    "df[\"Name\"] = df[\"Name\"].str.title() #Apply title case to names for better visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb95b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fatal cleaning\n",
    "df[\"Fatal Y/N\"]=df[\"Fatal Y/N\"].str.strip().str.title()\n",
    "df[\"Fatal Y/N\"]=df[\"Fatal Y/N\"].replace({\"F\": \"Unknown\", \"M\": \"Unknown\", \"Nq\": \"Unknown\", \"2017\": \"Unknown\", \"Y X 2\": \"Unknown\", \"Nan\": \"Unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bcfa96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#AGE\n",
    "df[\"Age\"]=df[\"Age\"].replace({\"?\":np.nan,\"Male\":np.nan,\"30+\":35,\"Middle age\":np.nan,\"40?\":40,\"40+\":40,\"60+\":60,\"30s\":35,\"20/30\":35,\"20s\":25,\"!2\":np.nan,\"50s\":55,\"40s\":45,\"teen\":15,\"Teen\":15,\"Male\":np.nan,\"!6\":np.nan,\"!!\":np.nan,\"60+\":65,\"40?\":40,\"18 months\":1,\"Teens\":15,\"8 or 10\":9,\"\\xa0 \":np.nan, \" \":np.nan,\"6½\":7,\"mid-30s\":35,\"16 to 18\":17,\n",
    "\"mid-20s\":25,\"Ca. 33\":33,\"45 \":45,\"9 months\":0,\"25 to 35\":30,\"25 or 28\":27,\" '37\":37,\"13 or 18\":16,\"7 or 8\":8,\"Female\":np.nan,\"9 or 10\":10,\"  \":np.nan,\"A.M.\":np.nan,\"10 or 12\":11,\"31 or 33\":32,\"2½\":3,\"13 or 14\":14,\"30 or 36\":33,\"MAKE LINE GREEN\":np.nan,\">50\":55,\"20's\":22,\"60s\":65,\"X\":np.nan,\n",
    "\"(adult)\":np.nan,\"60's\":65,\"2 to 3 months\":0,\"middle-age\":np.nan,\"adult\":np.nan,'\"middle-age\"':np.nan,\"Elderly\":70,\"12 or 13\":13,\"74 \":74,\"18 to 22\":20,\"33 or 37\":35,\"18 or 20\":19,\"a minor\":16,'\"young\"': np.nan,\"young\":np.nan,\"both 11\":11,\"?    &   14\":14,\"? & 19\":19})\n",
    "df[\"Age\"]=df[\"Age\"].astype(str).str.lower().str.strip()\n",
    "\n",
    "replacement={\n",
    "    \"and\": \"&\",\n",
    "    \"or\":\"&\",\n",
    "    \",\":\"&\",\n",
    "    \n",
    "}\n",
    "ages = df[\"Age\"].astype(str).str.lower()\n",
    "for old, new in replacement.items():\n",
    "    ages = ages.str.replace(old, new, regex=False)\n",
    "ages = ages.str.replace(r\"\\s+\", \"\", regex=True)\n",
    "ages=(ages.str.replace(r\"\\?+\", \"\", regex=True).str.replace(r\"&{2,}\", \"&\", regex=True).str.strip(\"&\"))\n",
    "def extract_numbers(text):\n",
    "    nums = re.findall(r\"\\d+\", text)\n",
    "    return [int(n) for n in nums] if nums else np.nan\n",
    "\n",
    "extracted = ages.apply(extract_numbers)\n",
    "df[\"Age\"] = extracted.apply(lambda x: np.mean(x).round(0) if isinstance(x, list) else np.nan)\n",
    "df[\"Age\"] = df[\"Age\"].astype(\"Int64\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85da1653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Year Column: \n",
    "df[\"Year\"]=(\n",
    "    df[\"Year\"].astype(\"string\").str.strip().str.extract(r\"(\\d{1,4})\")[0])\n",
    "df[\"Year\"]= pd.to_numeric(df[\"Year\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c13c6529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country\n",
    "df[\"Country\"] = df[\"Country\"].str.split('/').str[0]\n",
    "df[\"Country\"] = df[\"Country\"].str.replace(r'\\?\\s*\\(.*\\)', \"\", )\n",
    "df[\"Country\"] = df[\"Country\"].str.replace('?', '', regex=False)\n",
    "df[\"Country\"] = df[\"Country\"].str.strip().str.title()\n",
    "valid_countries = [\n",
    "    'United States', 'South Africa', 'Brazil', 'Maldives', 'Trinidad and Tobago',\n",
    "    'Saint Kitts and Nevis', 'Saint Martin', 'United Arab Emirates', 'Sri Lanka',\n",
    "    'Myanmar', 'Australia', 'Mexico', 'Costa Rica', 'Bahamas', 'Puerto Rico',\n",
    "    'French Polynesia', 'Spain', 'Canary Islands', 'Vanuatu', 'Jamaica',\n",
    "    'Israel', 'Philippines', 'Mozambique', 'New Caledonia', 'Egypt',\n",
    "    'Thailand', 'New Zealand', 'Hawaii', 'Honduras', 'Indonesia', 'Morocco',\n",
    "    'Belize', 'Cuba', 'Colombia', 'Ecuador', 'Seychelles', 'Argentina',\n",
    "    'Fiji', 'England', 'Japan', 'Canada', 'Jordan', 'Papua New Guinea',\n",
    "    'Reunion', 'China', 'Ireland', 'Italy', 'Malaysia', 'Libya', 'Mauritius',\n",
    "    'Solomon Islands', 'Cape Verde', 'Dominican Republic', 'Cayman Islands',\n",
    "    'Aruba', 'Portugal', 'Samoa', 'Kiribati', 'Taiwan', 'Palestinian Territories',\n",
    "    'Guam', 'Nigeria', 'Tonga', 'Scotland', 'Croatia', 'Saudi Arabia', 'Chile',\n",
    "    'Antigua', 'Kenya', 'Russia', 'South Korea', 'Malta', 'Vietnam',\n",
    "    'Madagascar', 'Panama', 'Somalia', 'British Virgin Islands', 'Norway',\n",
    "    'Senegal', 'Yemen', 'Liberia', 'Venezuela', 'Uruguay', 'Micronesia',\n",
    "    'Slovenia', 'Curacao', 'Iceland', 'Barbados', 'Monaco', 'Guyana', 'Haiti',\n",
    "    'San Domingo', 'Kuwait', 'Falkland Islands', 'Crete', 'Cyprus', 'Lebanon',\n",
    "    'Paraguay', 'Georgia', 'Syria', 'Tuvalu', 'Guinea', 'Equatorial Guinea',\n",
    "    'Cook Islands', 'Peru', 'Algeria', 'Ghana', 'Greenland', 'Sweden',\n",
    "    'Djibouti', 'Bahrein', 'Korea'\n",
    "]\n",
    "def fuzzy_match_country(name):\n",
    "    if pd.isnull(name):\n",
    "        return name\n",
    "    match, score = process.extractOne(name, valid_countries)\n",
    "    if score >= 85:  \n",
    "        return match\n",
    "    return name  \n",
    "df['Country'] = df['Country'].apply(fuzzy_match_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7d2d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    }
   ],
   "source": [
    "#State\n",
    "df[\"State\"] = df[\"State\"].str.replace('?', '', regex=False)\n",
    "df[\"State\"] = df[\"State\"].str.strip().str.title()\n",
    "\n",
    "valid_states =valid_states = [\n",
    "    # USA\n",
    "    'California', 'Florida', 'Texas', 'New York', 'North Carolina', 'South Carolina',\n",
    "    'Massachusetts', 'Georgia', 'Louisiana', 'Mississippi', 'Alabama', 'New Jersey',\n",
    "    'Washington', 'Oregon', 'Utah', 'Maryland', 'Virginia', 'Delaware', 'Rhode Island',\n",
    "    'Hawaii',\n",
    "\n",
    "    # Australia\n",
    "    'New South Wales', 'Queensland', 'Victoria', 'Western Australia', 'South Australia',\n",
    "    'Tasmania', 'Northern Territory',\n",
    "\n",
    "    # South Africa\n",
    "    'KwaZulu-Natal', 'Eastern Cape Province', 'Western Cape Province', 'Gauteng',\n",
    "    'Limpopo', 'Mpumalanga', 'Free State', 'North West', 'Northern Cape',\n",
    "\n",
    "    # New Zealand\n",
    "    'North Island', 'South Island', 'Auckland', 'Wellington', 'Canterbury', 'Otago',\n",
    "\n",
    "    # Papua New Guinea\n",
    "    'Central Province', 'Eastern Highlands', 'Western Highlands', 'Morobe', 'Madang',\n",
    "    'East Sepik', 'West Sepik', 'Milne Bay', 'New Ireland', 'Bougainville',\n",
    "\n",
    "    # Bahamas\n",
    "    'New Providence', 'Grand Bahama Island', 'Abaco Islands', 'Exumas', 'Eleuthera',\n",
    "    'Bimini', 'Andros Island', 'Berry Islands', 'Cat Island',\n",
    "\n",
    "    # Brazil\n",
    "    'São Paulo', 'Rio de Janeiro', 'Bahia', 'Pernambuco', 'Alagoas', 'Maranhão',\n",
    "    'Santa Catarina', 'Rio Grande Do Sul',\n",
    "\n",
    "    # Mexico\n",
    "    'Quintana Roo', 'Baja California', 'Baja California Sur', 'Jalisco', 'Sonora',\n",
    "    'Guerrero', 'Sinaloa', 'Tabasco', 'Tamaulipas', 'Colima',\n",
    "\n",
    "    # Italy\n",
    "    'Sardinia', 'Sicily', 'Tuscany', 'Lazio', 'Campania', 'Liguria', 'Veneto',\n",
    "    'Emilia-Romagna', 'Puglia', 'Calabria',\n",
    "\n",
    "    # Fiji\n",
    "    'Viti Levu', 'Vanua Levu', 'Taveuni Island', 'Yasawa Islands', 'Kadavu Island',\n",
    "\n",
    "    #Random cites from to 25 countries\n",
    "    'Florida', 'New South Wales', 'Queensland', 'Hawaii', 'California', 'Western Australia',\n",
    "    'KwaZulu-Natal', 'Western Cape Province', 'South Carolina', 'Eastern Cape Province',\n",
    "    'South Australia', 'North Carolina', 'Victoria', 'Texas', 'Pernambuco', 'North Island',\n",
    "    'Torres Strait', 'New Jersey', 'South Island', 'New York', 'Tasmania', 'Oregon',\n",
    "    'Abaco Islands', 'Central Province', 'Northern Territory'\n",
    "]\n",
    "\n",
    "\n",
    "# Step 3: Fuzzy match and replace\n",
    "def fuzzy_clean(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    match, score = process.extractOne(x, valid_states)\n",
    "    return match if score > 85 else x\n",
    "\n",
    "df['State_cleaned'] = df['State'].apply(fuzzy_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b6e916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAte\n",
    "def date_to_year_or_year_month(df, date_col=\"Date\", year_col=\"Year\"):\n",
    "    s = df[date_col]\n",
    "\n",
    "\n",
    "    if pd.api.types.is_datetime64_any_dtype(s):\n",
    "        \n",
    "        df[date_col] = s.dt.strftime(\"%Y-%m\")\n",
    "        return df\n",
    "\n",
    "\n",
    "    s = s.astype(str)\n",
    "    s = (s.str.replace(\"\\u00A0\", \" \", regex=False).str.replace(\"\\u200b\", \"\", regex=False).str.replace(r\"[\\[\\]]\", \"\", regex=True).str.replace(r\"(\\d{1,2})(st|nd|rd|th)\\b\", r\"\\1\", regex=True).str.replace(\",\", \"\", regex=False).str.replace(r\"\\s+\", \" \", regex=True).str.strip())\n",
    "\n",
    "    out = pd.Series(pd.NA, index=df.index, dtype=\"object\")\n",
    "    remaining = pd.Series(True, index=df.index)\n",
    "\n",
    "    m_range = remaining & s.str.fullmatch(r\"(\\d{3,4})\\s*[-–]\\s*(\\d{3,4})\", na=False)\n",
    "    if m_range.any():\n",
    "        y12 = s[m_range].str.extract(r\"(\\d{3,4})\\s*[-–]\\s*(\\d{3,4})\").astype(int)\n",
    "        mid = ((y12[0] + y12[1]) // 2).astype(int).astype(str)\n",
    "        out.loc[m_range] = mid\n",
    "        remaining &= ~m_range\n",
    "\n",
    " \n",
    "    m_qual = remaining & s.str.fullmatch(r\"(?i)(before|after|circa|about)\\s+(\\d{3,4})\", na=False)\n",
    "    if m_qual.any():\n",
    "        year = s[m_qual].str.extract(r\"(?i)(before|after|circa|about)\\s+(\\d{3,4})\")[1]\n",
    "        out.loc[m_qual] = year\n",
    "        remaining &= ~m_qual\n",
    "\n",
    "\n",
    "    m_year = remaining & s.str.fullmatch(r\"\\d{3,4}\", na=False)\n",
    "    if m_year.any():\n",
    "        out.loc[m_year] = s[m_year]\n",
    "        remaining &= ~m_year\n",
    "\n",
    "\n",
    "    if year_col in df.columns:\n",
    "        m_dm = remaining & s.str.match(r\"^\\d{1,2}\\s+[A-Za-z]+$\", na=False) & df[year_col].notna()\n",
    "        if m_dm.any():\n",
    "            s2 = s[m_dm] + \" \" + df.loc[m_dm, year_col].astype(\"Int64\").astype(str)\n",
    "            parsed_dm = pd.to_datetime(s2, errors=\"coerce\", dayfirst=True)\n",
    "            ok_idx = parsed_dm[parsed_dm.notna()].index\n",
    "            out.loc[ok_idx] = parsed_dm.loc[ok_idx].dt.strftime(\"%Y-%m\")\n",
    "            remaining &= ~remaining.index.isin(ok_idx)\n",
    "\n",
    "\n",
    "    if remaining.any():\n",
    "        parsed = pd.to_datetime(s[remaining], errors=\"coerce\", dayfirst=True, utc=False)\n",
    "        ok_idx = parsed[parsed.notna()].index\n",
    "        out.loc[ok_idx] = parsed.loc[ok_idx].dt.strftime(\"%Y-%m\")\n",
    "        remaining &= ~remaining.index.isin(ok_idx)\n",
    "\n",
    "\n",
    "    if remaining.any():\n",
    "        formats = [\"%Y-%m-%d %H:%M:%S\",\"%Y-%m-%d\",\"%d/%m/%Y %H:%M:%S\",\"%d/%m/%Y\",\"%m/%d/%Y %H:%M:%S\",\"%m/%d/%Y\"\"%Y-%m-%dT%H:%M:%S\",\"%Y-%m-%dT%H:%M:%S%z\",\"%Y-%m-%d %H:%M:%S%z\"]\n",
    "        r_idx = remaining[remaining].index\n",
    "        for fmt in formats:\n",
    "            if not remaining.any():\n",
    "                break\n",
    "            try:\n",
    "                parsed_fmt = pd.to_datetime(s[remaining], format=fmt, errors=\"coerce\")\n",
    "            except Exception:\n",
    "                continue\n",
    "            ok_idx = parsed_fmt[parsed_fmt.notna()].index\n",
    "            if len(ok_idx):\n",
    "                out.loc[ok_idx] = parsed_fmt.loc[ok_idx].dt.strftime(\"%Y-%m\")\n",
    "                remaining &= ~remaining.index.isin(ok_idx)\n",
    "\n",
    "    if remaining.any():\n",
    "        m_num = remaining & s.str.fullmatch(r\"\\d+(\\.\\d+)?\", na=False)\n",
    "        if m_num.any():\n",
    "            num = pd.to_numeric(s[m_num], errors=\"coerce\")\n",
    "            parsed_num = pd.to_datetime(num, unit=\"D\", origin=\"1899-12-30\", errors=\"coerce\")\n",
    "            ok_idx = parsed_num[parsed_num.notna()].index\n",
    "            out.loc[ok_idx] = parsed_num.loc[ok_idx].dt.strftime(\"%Y-%m\")\n",
    "            remaining &= ~remaining.index.isin(ok_idx)\n",
    "\n",
    "    df[date_col] = out\n",
    "    return df\n",
    "df=date_to_year_or_year_month(df, date_col=\"Date\", year_col=\"Year\")\n",
    "\n",
    "#Separate the year from the month and have them into two separate columns \n",
    "\n",
    "m = df[\"Date\"].astype(\"string\").str.strip().str.extract(\n",
    "    r\"^(?P<Year>\\d{4})(?:-(?P<Month>\\d{1,2}))?$\"\n",
    ")\n",
    "\n",
    "df[\"Year_from_date\"]  = pd.to_numeric(m[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"Month_from_date\"] = pd.to_numeric(m[\"Month\"], errors=\"coerce\").astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20457c34",
   "metadata": {},
   "source": [
    "                               Selecting to 10 countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05257522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_selected_country = Filtering for top 10 countries with most shark attacks\n",
    "df.Country.value_counts(ascending=False)\n",
    "selected_countries = [\"Usa\", \"Australia\", \"South Africa\", \"New Zealand\", \"Papua New Guinea\", \"Bahamas\", \"Brazil\", \"Mexico\", \"Italy\", \"Fiji\"]\n",
    "df_selected = df[df[\"Country\"].isin(selected_countries)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860433f",
   "metadata": {},
   "source": [
    "                              Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea32d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_country =  groupby country \n",
    "df_country = df_selected.groupby([\"Country\", \"Sex\"]).agg(\n",
    "    total_cases=(\"Fatal Y/N\", \"count\"),\n",
    "    fatal_yes=(\"Fatal Y/N\", lambda x: (x == \"Y\").sum()),\n",
    "    fatal_no=(\"Fatal Y/N\", lambda x: (x == \"N\").sum()),\n",
    "    avg_age=(\"Age\", \"mean\"))\n",
    "df_country_asc = df_country.sort_values(by=\"total_cases\", ascending=False)\n",
    "\n",
    "# df_country.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de315c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_state =  groupby state that has more thn 11 cases \n",
    "df_state = df_selected.groupby([\"Country\", \"State\", \"Sex\"]).agg(\n",
    "    total_cases=(\"Fatal Y/N\", \"count\"),\n",
    "    fatal_yes=(\"Fatal Y/N\", lambda x: (x == \"Y\").sum()),\n",
    "    fatal_no=(\"Fatal Y/N\", lambda x: (x == \"N\").sum()),\n",
    "    avg_age=(\"Age\", \"mean\"))   \n",
    "df_state = df_state[df_state[\"total_cases\"] >= 11]\n",
    "df_state_asc = df_state.sort_values(by=\"total_cases\", ascending=False)\n",
    "# df_state.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8abd202",
   "metadata": {},
   "source": [
    "                    Use the following dataframe\n",
    "\n",
    "                        df_country =  groupby country \n",
    "                        df_country_asc =  groupby country ascending\n",
    "\n",
    "                        df_state =  groupby state that has more thn 11 cases \n",
    "                        df_state_asc =  groupby state that has more thn 11 cases ascending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a74ddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for df_country:\n",
      "******************************\n",
      "Overall avg age: 27.31740744588467\n",
      "Total males: 4107\n",
      "Total females: 604\n",
      "Total cases: 4712\n",
      "Total fatal yes: 822\n",
      "Total fatal no: 3859\n",
      "Male percentage of total cases: 87.16044142614601\n",
      "Female percentage of total cases: 12.818336162988114\n",
      "Male fatality rate (%): 18.407596785975162\n",
      "Female fatality rate (%): 10.927152317880795\n",
      "Overall fatality rate (%): 17.44482173174873\n"
     ]
    }
   ],
   "source": [
    "# Calculations from df_country\n",
    "overall_avg_age = df_country[\"avg_age\"].mean()\n",
    "\n",
    "total_males = df_country.loc[df_country.index.get_level_values(\"Sex\") == \"M\", \"total_cases\"].sum()\n",
    "total_females = df_country.loc[df_country.index.get_level_values(\"Sex\") == \"F\", \"total_cases\"].sum()\n",
    "\n",
    "fatal_males = df_country.loc[df_country.index.get_level_values(\"Sex\") == \"M\", \"fatal_yes\"].sum()\n",
    "fatal_females = df_country.loc[df_country.index.get_level_values(\"Sex\") == \"F\", \"fatal_yes\"].sum()\n",
    "\n",
    "total_cases_all = df_country[\"total_cases\"].sum()\n",
    "total_fatal_yes = df_country[\"fatal_yes\"].sum()\n",
    "total_fatal_no = df_country[\"fatal_no\"].sum()\n",
    "\n",
    "fatality_rate_males = (fatal_males / total_males) * 100\n",
    "fatality_rate_females = (fatal_females / total_females) * 100\n",
    "overall_fatality_rate = (total_fatal_yes / total_cases_all) * 100\n",
    "\n",
    "print(\"Statistics for df_country:\")\n",
    "print(\"*\" *30)\n",
    "print(\"Overall avg age:\", overall_avg_age)\n",
    "print(\"Total males:\", total_males)\n",
    "print(\"Total females:\", total_females)\n",
    "print(\"Total cases:\", total_cases_all)\n",
    "print(\"Total fatal yes:\", total_fatal_yes)\n",
    "print(\"Total fatal no:\", total_fatal_no)\n",
    "print(\"Male percentage of total cases:\", (total_males / total_cases_all) * 100)\n",
    "print(\"Female percentage of total cases:\", (total_females / total_cases_all) * 100)\n",
    "print(\"Male fatality rate (%):\", fatality_rate_males)\n",
    "print(\"Female fatality rate (%):\", fatality_rate_females)\n",
    "print(\"Overall fatality rate (%):\", overall_fatality_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71844a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_country.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f78a02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_country_asc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d8ab9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_state.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca324e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_state_asc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ba181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919407a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
